ğŸ•·ï¸ Krauler

Clean, AI-ready web crawler for invention pipelines, research, and data mining.

Krauler is a lightweight, async-first web crawling framework with a Streamlit-powered UI, LLM-ready outputs, and self-healing diagnostics. Itâ€™s built for researchers, inventors, and builders who want to gather structured data fast â€” without wrestling with bloated scraping frameworks.

âœ¨ Features

ğŸš€ Async-first engine â†’ powered by aiohttp, playwright, and stealth browsing

ğŸ§  LLM-ready outputs â†’ crawl data structured for AI/ML pipelines (JSONL, CSV)

ğŸ–¼ Streamlit dashboard â†’ no CLI required; paste URLs, run crawls, see results

ğŸ” Flexible extraction â†’ text, metadata, links, images

ğŸ”„ Self-healing diagnostics â†’ detects broken imports, pyproject issues, missing deps

âš¡ Extensible â†’ plug in rankers (BM25, embeddings), custom agents, or export pipelines

ğŸ›  Developer-friendly â†’ simple config, modular design, ready for CI/CD

ğŸ“¦ Installation
# clone your fork
git clone https://github.com/your-username/krauler.git
cd krauler

# install in editable mode
pip install -e .[all]

# install playwright browsers
playwright install

ğŸ–¥ï¸ Usage
ğŸ”¹ Command Line
# run a basic crawl
python -m krauler.cli https://example.com --depth 2 --text

ğŸ”¹ Streamlit App
streamlit run ui/app.py --server.port 8501


Then open http://localhost:8501
 in your browser.
From there, you can:

Paste one or more URLs

Set crawl depth

Select extraction mode (text, images, metadata)

View live results

Export to JSON or CSV

ğŸ§­ Project Structure
krauler/
â”œâ”€â”€ src/krauler/         # core package
â”‚   â”œâ”€â”€ core/            # crawler engine
â”‚   â”œâ”€â”€ parsers/         # HTML/data parsers
â”‚   â”œâ”€â”€ storage/         # async storage (sqlite/jsonl)
â”‚   â”œâ”€â”€ ui/              # Streamlit app
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ui/app.py            # main Streamlit dashboard
â”œâ”€â”€ tests/               # pytest suite
â”œâ”€â”€ pyproject.toml       # project config
â””â”€â”€ README.md

ğŸ§ª Development
Run tests
pytest

Lint + type check
ruff check .
mypy src/krauler

Build package
python -m build

ğŸš¦ CI/CD

âœ… PRs â†’ Publish to TestPyPI

âœ… Tags (vX.Y.Z) â†’ Publish to PyPI

âœ… Docker image auto-builds at ghcr.io/<owner>/krauler:latest

ğŸ§  Why Krauler?

Unlike heavyweights like Scrapy, Krauler is:

Lightweight (no spiders/config bloat)

Async-native (no thread hell)

LLM-focused (outputs structured chunks for embedding/training)

UI-first (Streamlit dashboard = no barrier to entry)

Itâ€™s not just a crawler â€” itâ€™s a data-gathering workbench for the AI era.

ğŸ“œ License

Apache 2.0 â€” free to use, modify, and share.

ğŸ¤ Contributing

Contributions welcome!

Fork the repo

Create a feature branch

Submit a PR

â­ Acknowledgements

Built with inspiration from:

Playwright

BeautifulSoup

Streamlit

litellm

ğŸ”¥ Ready to crawl the web smarter? Start with:

streamlit run ui/app.py
